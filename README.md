# YACAI (Yet Another Chess AI)

Planning (aka Drew's rambling thoughts):

1. We need some sort of board representation that we can track game state and extract features from. Originally I was thinking we could start off helping Abhay do this with his newly acquired python skills, but then I found this: https://python-chess.readthedocs.io/en/latest/core.html. This looks awesome and is really easy to use. It provides parsing tools for reading in chess games from standard notation and also provides interfaces that let you create a board and apply moves to it. You can even get pieces being attacked by similar pieces and lists of all available moves. In 15 minutes I was able to parse a game in and iterate the game state after every move on a board object and generate an image for every state. Using this would mean that we can save hours developing an engine and just start with determining what heuristics and features we care about right away.
  
2. I found a nice dataset: https://www.kaggle.com/datasnaek/chess. I tested the format the moves are given in and it is compatable with the python-chess library. It is a litlle small though (20k games), so if we could find another one it may be good to either use that one or combine them.
  
3. The text format of representing chess games is called PGN (https://en.wikipedia.org/wiki/Portable_Game_Notation). This is what both python-chess and the dataset use. it is however very flexible and works with a lot of data that doesn't directly align to the exact notation. (Abhay wanted this included)
  
4. AI is weird but here are my ideas - Sunbeam/Shreyash you need to correct me / add your own stuff
  * Fundamentally a chess AI is a tree search problem. We could implement an AI that scores the state of a board based on hand selected features and weights and uses these feataures and weights to prune off branches.
  * We can expand on this by using randomly generated features and game states from database games in neural net fashion - i'm not sure what the training data would be. The games are labeled by winner and individual states do not have quality's attached. We could determine the quality score of a position as a function of the who won and what move number the game is on, but I'm not sure how well this would represent the actual quality of the position since human players make suboptimal moves and one player could have a better position all the way up until they are checkmated. Using heuristics to assign qaulities and then extracting features relevant to determing that quality is not useful since there is circular logic.

5. We may take a Reinforcement Learning approach. This is the only approach I myself understand how it may be done well from start to finish. Sunbeam would have to expand on the deep learning stuff if we do that. The RL approach may not even need a pre-existing dataset, but it may be useful to use the dataset for something like seeding to get a headstart and so that it can do things like make proper openings. There is a python library called python-neat (https://neat-python.readthedocs.io/en/latest/index.html) that uses evolutionary algorithms to create neural networks. Using this would require us to figure out two things: how to parameterize a chess playing agent (hardest), and how to determine the fitness of a particular set of parameters applied to our decision making agent (kinda hard maybe depending on how neat works).

  * Creating a parameterized agent is hard. Keeping in mind that chess is a tree search problem, and that picking a move is equivalent to selecting the next state of the game, the paramatization of the agent can be a set of weights of different features of a game state used to calculate the quality of a state. This makes it such that the aagents are distinguished from each other by the function they use to determine the quality of a game state. With well selected features that are able to encapsulate something that actually represents something close to the true quality of the board this should work. At least Some of the features selected MUST take into account possible future states (this is a tree search problem and its important to search the tree).

  * Determining the fitness is where the RL stuff may come into play. Since we have multiple decision making agents we may play them agaainst each other. (The chess engine in section 1 makes this easy) Playing them in a bracket style is one way of determining fitness - winners of the brackets get high fitness while the loosers get low fitness. The problem with this is that conventionally evolutionary algorithms take 1 individual member of the population as a parameter and return a fitness that is independent of the other members of the population. I think that determining the agents relative fitnesses will work in theory, but it may be tricky to get the NEAT library to be okay with that. We will have to find a place in the code to run all of the game simulations and calculate ranks which means somewhere we need to figure out how to call a function with a list of the entire population. The fitness function itself will likely not be much more complicated than an array or dictionary lookup.
  * The quality of the different agents (and human chess players) is not transitive (ie. A beats B and B beats C does not imply that a will beat C). This is a flaw in the bracket strategy of ranking and we may either accept this flaw or make a modification to improve on it. One thing we might do is have the top 10 placers in the standard bracket all play one another in 45 different game simulations. This would allow us to better rank the best agents which are the agents we care about the most. Another might be to run the bracket 10 times with different starting positions for the agents each time and averaging each agents final placement and calling that their rank.  The more games we have to simulate means the longer it'll take and the fewer iterations we can run, so we definately don't want to play every agent in the population against every other (since the population will likely be in the thousands), but I think we'll need something better than a basic bracket.

Links for Quantum Computing
* Qiskit installation: https://qiskit.org/documentation/install.html#access-ibm-quantum-systems
* Quiskit Hello World: https://qiskit.org/documentation/tutorials/circuits/1_getting_started_with_qiskit.html

Links for RL 
* RL and Chess: https://colab.research.google.com/drive/1Xk9MibJ9Fli5tIlDvo88hcZrI76rqZN5#scrollTo=VLNm1D9s_O0O